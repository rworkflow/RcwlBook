[["index.html", "Bioinformatics tools and pipelines using R and CWL Preface 0.1 R package installation 0.2 System requirements 0.3 Docker 0.4 Structure of the book 0.5 R session information", " Bioinformatics tools and pipelines using R and CWL Qiang Hu Qian Liu 2021-02-27 Preface This book introduces the R/Bioconductor packages, Rcwl and RcwlPipelines, to improve the way of building, managing and running Bioinformatics tools and pipelines within R. The Rcwl package is built on top of the Common Workflow Language (CWL), and provides a simple and user-friendly way to wrap command line tools into data analysis pipelines in R. The RcwlPipelines package manages a collection of bioinformatics tools and pipelines based on Rcwl. 0.1 R package installation The Rcwl and RcwlPipelines packages can be installed from Bioconductor or Github: BiocManager::install(c(&quot;Rcwl&quot;, &quot;RcwlPipelines&quot;)) # or the development version BiocManager::install(c(&quot;rworkflow/Rcwl&quot;, &quot;rworkflow/RcwlPipelines&quot;)) To load the packages into R session: library(Rcwl) library(RcwlPipelines) 0.2 System requirements In addition to the R packages, the following tools are also required to successfully run the tools/pipelines. If not locally available, these tools will be installed automatically, powered by the basilisk package. python (&gt;= 2.7) cwltool (&gt;= 1.0.2018) nodejs The cwltool is the reference implementation of the Common Workflow Language, which is used to run the CWL scripts. The nodejs is required when the CWL scripts use JavaScript. More details about these tools can be found here: * https://github.com/common-workflow-language/cwltool * https://nodejs.org 0.3 Docker The Docker container simplifies software installation and management, especially for bioinformatics tools/pipelines requiring different runtime environments and library dependencies. A CWL runner can perform this work automatically by pulling the Docker containers and mounting the paths of input files. The Docker requirement is optional, as CWL scripts can also be run locally with all the dependencies pre-installed. 0.4 Structure of the book Introduction Get started Wrap command line tools Writing Pipeline Tool/pipeline execution RcwlPipelines DNAseq alignment DNAseq variant calling Bulk RNAseq Single cell RNAseq miRNA 0.5 R session information The R session information for compiling this mannual is shown below: sessionInfo() ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-apple-darwin13.4.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS/LAPACK: /Users/qi31566/miniconda3/envs/r-base/lib/libopenblasp-r0.3.12.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] bookdown_0.21 DropletUtils_1.10.3 ## [3] SingleCellExperiment_1.12.0 SummarizedExperiment_1.20.0 ## [5] Biobase_2.50.0 GenomicRanges_1.42.0 ## [7] GenomeInfoDb_1.26.2 IRanges_2.24.1 ## [9] MatrixGenerics_1.2.1 matrixStats_0.58.0 ## [11] BiocStyle_2.18.1 BiocParallel_1.24.1 ## [13] RcwlPipelines_1.7.7 BiocFileCache_1.14.0 ## [15] dbplyr_2.1.0 Rcwl_1.7.12 ## [17] S4Vectors_0.28.1 BiocGenerics_0.36.0 ## [19] yaml_2.2.1 ## ## loaded via a namespace (and not attached): ## [1] ellipsis_0.3.1 rprojroot_2.0.2 ## [3] scuttle_1.0.4 XVector_0.30.0 ## [5] fs_1.5.0 rstudioapi_0.13 ## [7] remotes_2.2.0 bit64_4.0.5 ## [9] fansi_0.4.2 sparseMatrixStats_1.2.1 ## [11] codetools_0.2-18 R.methodsS3_1.8.1 ## [13] cachem_1.0.4 knitr_1.31 ## [15] pkgload_1.2.0 jsonlite_1.7.2 ## [17] R.oo_1.24.0 HDF5Array_1.18.1 ## [19] shiny_1.6.0 DiagrammeR_1.0.6.1 ## [21] BiocManager_1.30.10 compiler_4.0.3 ## [23] httr_1.4.2 dqrng_0.2.1 ## [25] basilisk_1.2.1 backports_1.2.1 ## [27] assertthat_0.2.1 Matrix_1.3-2 ## [29] fastmap_1.1.0 limma_3.46.0 ## [31] cli_2.3.1 later_1.1.0.1 ## [33] visNetwork_2.0.9 htmltools_0.5.1.1 ## [35] prettyunits_1.1.1 tools_4.0.3 ## [37] igraph_1.2.6 glue_1.4.2 ## [39] GenomeInfoDbData_1.2.4 dplyr_1.0.4 ## [41] batchtools_0.9.15 rappdirs_0.3.3 ## [43] tinytex_0.29 Rcpp_1.0.6 ## [45] jquerylib_0.1.3 rhdf5filters_1.2.0 ## [47] vctrs_0.3.6 DelayedMatrixStats_1.12.3 ## [49] xfun_0.21 stringr_1.4.0 ## [51] ps_1.5.0 beachmat_2.6.4 ## [53] testthat_3.0.2 mime_0.10 ## [55] lifecycle_1.0.0 devtools_2.3.2 ## [57] edgeR_3.32.1 zlibbioc_1.36.0 ## [59] basilisk.utils_1.2.2 hms_1.0.0 ## [61] promises_1.2.0.1 rhdf5_2.34.0 ## [63] RColorBrewer_1.1-2 curl_4.3 ## [65] memoise_2.0.0 reticulate_1.18 ## [67] sass_0.3.1 stringi_1.5.3 ## [69] RSQLite_2.2.3 desc_1.2.0 ## [71] checkmate_2.0.0 filelock_1.0.2 ## [73] pkgbuild_1.2.0 rlang_0.4.10 ## [75] pkgconfig_2.0.3 bitops_1.0-6 ## [77] evaluate_0.14 lattice_0.20-41 ## [79] Rhdf5lib_1.12.1 purrr_0.3.4 ## [81] htmlwidgets_1.5.3 bit_4.0.4 ## [83] processx_3.4.5 tidyselect_1.1.0 ## [85] magrittr_2.0.1 R6_2.5.0 ## [87] generics_0.1.0 base64url_1.4 ## [89] DelayedArray_0.16.1 DBI_1.1.1 ## [91] pillar_1.5.0 withr_2.4.1 ## [93] RCurl_1.98-1.2 tibble_3.0.6 ## [95] crayon_1.4.1 utf8_1.1.4 ## [97] rmarkdown_2.7 progress_1.2.2 ## [99] usethis_2.0.1 locfit_1.5-9.4 ## [101] grid_4.0.3 data.table_1.14.0 ## [103] blob_1.2.1 callr_3.5.1 ## [105] git2r_0.28.0 digest_0.6.27 ## [107] xtable_1.8-4 tidyr_1.1.2 ## [109] httpuv_1.5.5 brew_1.0-6 ## [111] R.utils_2.10.1 bslib_0.2.4 ## [113] sessioninfo_1.1.1 "],["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction The bioinformatics community increasingly relies on ‘workflow’ frameworks to manage large and complex biomedical data (Köster and Rahmann, 2012; Di Tommaso et al., 2017). One solution facilitating portable, reproducible, and scalable workflows across a variety of software and hardware environments is the Common Workflow Language (CWL) (Amstutz et al., 2016). “The Common Workflow Language (CWL) is a specification for describing analysis workflows and tools in a way that makes them portable and scalable across a variety of software and hardware environments, from workstations to cluster, cloud, and high performance computing (HPC) environments.” The CWL has been widely adopted by large biomedical projects such as The Cancer Genome Atlas (TCGA) (Weinstein et al., 2013) and Galaxy (Afgan et al., 2018). However, as a domain-specific language, the implementation of CWL requires a level of expertise that is often beyond the capabilities of wet-lab researchers and even skilled data scientists. In addition, the impact of CWL pipelines is weakened by poor integration with downstream statistical analysis tools such as R and Bioconductor (Huber et al., 2015; Amezquita et al., 2020). In this book, we introduce a Bioconductor toolchain for use and development of reproducible bioinformatics pipelines in CWL using Rcwl and RcwlPipelines. Rcwl provides a familiar R interface to, and expands the scope of, CWL. Rcwl enables best practices and standardized data flow between different tools, and promotes modularization for easy sharing of established pipelines or critical steps. RcwlPipelines is a collection of commonly used bioinformatics tools and pipeline recipes based on Rcwl.RcwlPipelines develops a community-driven platform for open source, open development, and open review of best-practice CWL bioinformatics pipelines. Rcwl and RcwlPipelines reduces the learning curve required to apply findable, accessible, interoperable, and reusable (FAIR) principles to the analysis of multi-omics biological experiments, and to promote community-wide sharing of cloud-ready bioinformatics workflows. "],["get-started.html", "Chapter 2 Get started", " Chapter 2 Get started cwlProcess is the main constructor function to wrap a command line tool into an R tool as a cwlProcess object (S4 class). Let’s start with a simple example to wrap the echo command and execute echo hello world in R. First, we need to define the input parameter for the base command echo, here it is a string without a prefix. An id argument is required here. input1 &lt;- InputParam(id = &quot;sth&quot;) Second, we can construct a cwlProcess object by specifying the baseCommand for the command line tool, and InputParamList for the input parameters. echo &lt;- cwlProcess(baseCommand = &quot;echo&quot;, inputs = InputParamList(input1)) Now we have converted the command line tool echo into an R tool: an R object of class cwlProcess with the name of echo. We can take a look at the this R object and use some utility functions to extract specific information. echo ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## sth (string): ## outputs: ## output: ## type: stdout class(echo) ## [1] &quot;cwlProcess&quot; ## attr(,&quot;package&quot;) ## [1] &quot;Rcwl&quot; cwlClass(echo) ## [1] &quot;CommandLineTool&quot; cwlVersion(echo) ## [1] &quot;v1.0&quot; baseCommand(echo) ## [1] &quot;echo&quot; inputs(echo) ## inputs: ## sth (string): outputs(echo) ## outputs: ## output: ## type: stdout The inputs(echo) will show the value once it is assigned in next step. Since we didn’t define the outputs for this tool, it will stream standard output to a temporary file by default. The third step is to assign values (here is “Hello World!”) for the input parameters. echo$sth &lt;- &quot;Hello World!&quot; inputs(echo) ## inputs: ## sth (string): Hello World! Now this R version of command line tool echo is ready to be executed. The function runCWL runs the tools in R and returns a list of: 1) actual command line that was executed, 2) filepath to the output, and 3) running logs. The output directory by default takes the working directory, but can be specified in outdir argument. r1 &lt;- runCWL(echo, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r1 ## List of length 3 ## names(3): command output logs r1$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job echo.cwl] /private/tmp/docker_tmptw4l9_2r$ echo \\\\&quot; ## [2] &quot; &#39;Hello World!&#39; &gt; /private/tmp/docker_tmptw4l9_2r/36a045913589936efd476118f8e7f986eb86e995&quot; readLines(r1$output) ## [1] &quot;Hello World!&quot; r1$logs ## [1] &quot;\\033[1;30mINFO\\033[0m /Users/qi31566/Library/Python/3.7/bin/cwltool 3.0.20200324120055&quot; ## [2] &quot;\\033[1;30mINFO\\033[0m Resolved &#39;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T//RtmptDExzb/file82097749d3b5/echo.cwl&#39; to &#39;file:///var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/file82097749d3b5/echo.cwl&#39;&quot; ## [3] &quot;\\033[1;30mINFO\\033[0m [job echo.cwl] /private/tmp/docker_tmptw4l9_2r$ echo \\\\&quot; ## [4] &quot; &#39;Hello World!&#39; &gt; /private/tmp/docker_tmptw4l9_2r/36a045913589936efd476118f8e7f986eb86e995&quot; ## [5] &quot;\\033[1;30mINFO\\033[0m [job echo.cwl] completed success&quot; ## [6] &quot;{&quot; ## [7] &quot; \\&quot;output\\&quot;: {&quot; ## [8] &quot; \\&quot;location\\&quot;: \\&quot;file:///var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/36a045913589936efd476118f8e7f986eb86e995\\&quot;,&quot; ## [9] &quot; \\&quot;basename\\&quot;: \\&quot;36a045913589936efd476118f8e7f986eb86e995\\&quot;,&quot; ## [10] &quot; \\&quot;class\\&quot;: \\&quot;File\\&quot;,&quot; ## [11] &quot; \\&quot;checksum\\&quot;: \\&quot;sha1$a0b65939670bc2c010f4d5d6a0b3e4e4590fb92b\\&quot;,&quot; ## [12] &quot; \\&quot;size\\&quot;: 13,&quot; ## [13] &quot; \\&quot;path\\&quot;: \\&quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/36a045913589936efd476118f8e7f986eb86e995\\&quot;&quot; ## [14] &quot; }&quot; ## [15] &quot;}&quot; ## [16] &quot;\\033[1;30mINFO\\033[0m Final process status is success&quot; Users can also have the log printed out by specifying showLog = TRUE. r1 &lt;- runCWL(echo, outdir = tempdir(), showLog = TRUE) ## } A utility function writeCWL converts the cwlProcess object into 2 files: a .cwl file for the command and .yml file for the inputs, which are the internal cwl files to be executed when runCWL is invoked. The internal execution requires a cwl-runner (e.g., cwltool), which will be installed automatically with runCWL. writeCWL(echo) ## cwlout ## &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T//RtmptDExzb/file82096fb8655b/echo.cwl&quot; ## ymlout ## &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T//RtmptDExzb/file82096fb8655b/echo.yml&quot; "],["wrap-command-line-tools.html", "Chapter 3 Wrap command line tools 3.1 Input Parameters 3.2 Output Parameters", " Chapter 3 Wrap command line tools 3.1 Input Parameters 3.1.1 Essential Input parameters For the input parameters, three options need to be defined usually, id, type, and prefix. The type can be string, int, long, float, double, and so on. More detail can be found at: https://www.commonwl.org/v1.0/CommandLineTool.html#CWLType. Here is an example from CWL user guide. Here we defined an echo with different type of input parameters by InputParam. The stdout option can be used to capture the standard output stream to a file. e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;) e4 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) echoA &lt;- cwlProcess(baseCommand = &quot;echo&quot;, inputs = InputParamList(e1, e2, e3, e4), stdout = &quot;output.txt&quot;) Then we can assign values for the input parameters. echoA$flag &lt;- TRUE echoA$string &lt;- &quot;Hello&quot; echoA$int &lt;- 1 tmpfile &lt;- tempfile() write(&quot;World&quot;, tmpfile) echoA$file &lt;- tmpfile r2 &lt;- runCWL(echoA, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r2$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job echoA.cwl] /private/tmp/docker_tmpxhmbf59f$ echo \\\\&quot; ## [2] &quot; --file=/private/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/tmp94ebi5hg/stge8b3fed3-6918-40e6-8f75-0f443460f4d0/file82097fdeaaa5 \\\\&quot; ## [3] &quot; -f \\\\&quot; ## [4] &quot; -i \\\\&quot; ## [5] &quot; 1 \\\\&quot; ## [6] &quot; -s \\\\&quot; ## [7] &quot; Hello &gt; /private/tmp/docker_tmpxhmbf59f/output.txt&quot; The command shows the parameters work as we defined. The parameters are in alphabetical orders by default, but can be modified by the position argument in InputParam function. 3.1.2 Array Inputs A similar example to CWL user guide. We can define three different type of array as inputs. a1 &lt;- InputParam(id = &quot;A&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;) a2 &lt;- InputParam(id = &quot;B&quot;, type = InputArrayParam(items = &quot;string&quot;, prefix=&quot;-B=&quot;, separate = FALSE)) a3 &lt;- InputParam(id = &quot;C&quot;, type = &quot;string[]&quot;, prefix = &quot;-C=&quot;, itemSeparator = &quot;,&quot;, separate = FALSE) echoB &lt;- cwlProcess(baseCommand = &quot;echo&quot;, inputs = InputParamList(a1, a2, a3)) Then we can assign values for the three input parameters: echoB$A &lt;- letters[1:3] echoB$B &lt;- letters[4:6] echoB$C &lt;- letters[7:9] echoB ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## A (string[]): -A a b c ## B: ## type: array ## prefix: -B= d e f ## C (string[]): -C= g h i ## outputs: ## output: ## type: stdout Now we can check whether the command behaves as we expected. r3 &lt;- runCWL(echoB, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r3$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job echoB.cwl] /private/tmp/docker_tmpn93lkfs0$ echo \\\\&quot; ## [2] &quot; -A \\\\&quot; ## [3] &quot; a \\\\&quot; ## [4] &quot; b \\\\&quot; ## [5] &quot; c \\\\&quot; ## [6] &quot; -B=d \\\\&quot; ## [7] &quot; -B=e \\\\&quot; ## [8] &quot; -B=f \\\\&quot; ## [9] &quot; -C=g,h,i &gt; /private/tmp/docker_tmpn93lkfs0/d24089c4b17d2ef479f4cdeb037297507021ddb1&quot; 3.2 Output Parameters 3.2.1 Capturing Output Similar to the input parameters, the output is a list of output parameters. Three options id, type and glob can be defined. The glob option is used to define a pattern to find files relative to the output directory. Here is an example to unzip a compressed gz file. First, we generate a compressed R script file. zzfil &lt;- file.path(tempdir(), &quot;sample.R.gz&quot;) zz &lt;- gzfile(zzfil, &quot;w&quot;) cat(&quot;sample(1:10, 5)&quot;, file = zz, sep = &quot;\\n&quot;) close(zz) Then we build a tool called gz (a cwlProcess object) to uncompress a input file using ‘gzip’. ofile &lt;- &quot;sample.R&quot; z1 &lt;- InputParam(id = &quot;uncomp&quot;, type = &quot;boolean&quot;, prefix = &quot;-d&quot;) z2 &lt;- InputParam(id = &quot;out&quot;, type = &quot;boolean&quot;, prefix = &quot;-c&quot;) z3 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) gz &lt;- cwlProcess(baseCommand = &quot;gzip&quot;, inputs = InputParamList(z1, z2, z3), outputs = OutputParamList(o1), stdout = ofile) Now the gz is ready to uncompress the previous generated compressed file. gz$uncomp &lt;- TRUE gz$out &lt;- TRUE gz$zfile &lt;- zzfil r4 &lt;- runCWL(gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r4$output ## [1] &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/sample.R&quot; We can use arguments argument to modify some default parameters. z1 &lt;- InputParam(id = &quot;zfile&quot;, type = &quot;File&quot;) o1 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = ofile) Gz &lt;- cwlProcess(baseCommand = &quot;gzip&quot;, arguments = list(&quot;-d&quot;, &quot;-c&quot;), inputs = InputParamList(z1), outputs = OutputParamList(o1), stdout = ofile) Gz ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: gzip ## arguments: -d -c ## inputs: ## zfile (File): ## outputs: ## rfile: ## type: File ## outputBinding: ## glob: sample.R ## stdout: sample.R Gz$zfile &lt;- zzfil r4a &lt;- runCWL(Gz, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success To make it for general usage, we can define a pattern with javascript to glob the output, which requires node from ‘nodejs’ to be installed in your system PATH. pfile &lt;- &quot;$(inputs.zfile.path.split(&#39;/&#39;).slice(-1)[0].split(&#39;.&#39;).slice(0,-1).join(&#39;.&#39;))&quot; Or we can use the CWL built-in file property, nameroot, directly. pfile &lt;- &quot;$(inputs.zfile.nameroot)&quot; o2 &lt;- OutputParam(id = &quot;rfile&quot;, type = &quot;File&quot;, glob = pfile) req1 &lt;- requireJS() GZ &lt;- cwlProcess(baseCommand = &quot;gzip&quot;, arguments = list(&quot;-d&quot;, &quot;-c&quot;), requirements = list(), ## assign list(req1) if node installed. inputs = InputParamList(z1), outputs = OutputParamList(o2), stdout = pfile) GZ$zfile &lt;- zzfil r4b &lt;- runCWL(GZ, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success 3.2.2 Array Outputs We can also capture multiple output files with glob pattern. a &lt;- InputParam(id = &quot;a&quot;, type = InputArrayParam(items = &quot;string&quot;)) b &lt;- OutputParam(id = &quot;b&quot;, type = OutputArrayParam(items = &quot;File&quot;), glob = &quot;*.txt&quot;) touch &lt;- cwlProcess(baseCommand = &quot;touch&quot;, inputs = InputParamList(a), outputs = OutputParamList(b)) touch$a &lt;- c(&quot;a.txt&quot;, &quot;b.log&quot;, &quot;c.txt&quot;) r5 &lt;- runCWL(touch, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r5$output ## [1] &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/a.txt&quot; ## [2] &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/c.txt&quot; The ‘touch’ command generates three files, but the output only collects two files with ‘.txt’ suffix as defined in the OutputParam using the ‘glob’ option. 3.2.3 Standard output Usually, the stdout option is a string or an expression of output file name from the command line tool. The command’s standard output stream will be captured into a file written to the designated output directory. When the stdout field is defined, an output parameter with the type of “stdout” should be also assigned with no “outputBinding” set. An example for command tool “cat” is defined with stdout field in the output, with the name passed from the input parameter “p2”: ## define Cat p1 &lt;- InputParam(id = &quot;infiles&quot;, type = &quot;File[]&quot;) p2 &lt;- InputParam(id = &quot;outfile&quot;, type = &quot;string&quot;, default = &quot;catout.txt&quot;, position = -1) Cat &lt;- cwlProcess(baseCommand = &quot;cat&quot;, inputs = InputParamList(p1, p2), stdout = &quot;$(inputs.outfile)&quot;) ## assign values to inputs afile &lt;- file.path(tempdir(), &quot;a.txt&quot;) bfile &lt;- file.path(tempdir(), &quot;b.txt&quot;) write(&quot;a&quot;, afile) write(&quot;b&quot;, bfile) Cat$infiles &lt;- list(afile, bfile) ## run the tool r6 &lt;- runCWL(Cat, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r6$command ## [1] &quot;\\033[1;30mINFO\\033[0m [job Cat.cwl] /private/tmp/docker_tmpt0o68s_7$ cat \\\\&quot; ## [2] &quot; /private/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/tmpzenr6hg0/stg3e2af0d4-9366-4269-8873-52956719a84f/a.txt \\\\&quot; ## [3] &quot; /private/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/tmpzenr6hg0/stg14e37ece-450b-4796-b431-1fb34a2eed1b/b.txt &gt; /private/tmp/docker_tmpt0o68s_7/catout.txt&quot; In this example, we used the parameter “p2” to pass the name to the standard output. In the InputParam of “p2”, the position is assigned to a negative value (-1), which means the parameters will not be used in the command and only uses for passing variable. To write the “Cat” tool to a CWL file, the “inputBinding” field will be skipped for this parameter. "],["writing-pipeline.html", "Chapter 4 Writing Pipeline 4.1 Scattering pipeline 4.2 Pipeline plot", " Chapter 4 Writing Pipeline We can connect multiple tools together into a pipeline. Here is an example to uncompress an R script and execute it with Rscript. Here we define a simple Rscript tool without using docker. d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) Rs &lt;- cwlProcess(baseCommand = &quot;Rscript&quot;, inputs = InputParamList(d1)) Rs ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: Rscript ## inputs: ## rfile (File): ## outputs: ## output: ## type: stdout Test run: Rs$rfile &lt;- r4$output tres &lt;- runCWL(Rs, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(tres$output) ## [1] &quot;[1] 10 7 2 5 8&quot; The pipeline includes two steps, decompressing with predefined cwlProcess of GZ and compiling with cwlProcess of Rs. The input file is a compressed file for the first “Uncomp” step. i1 &lt;- InputParam(id = &quot;cwl_zfile&quot;, type = &quot;File&quot;) s1 &lt;- cwlStep(id = &quot;Uncomp&quot;, run = GZ, In = list(zfile = &quot;cwl_zfile&quot;)) s2 &lt;- cwlStep(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;Uncomp/rfile&quot;)) In step 1 (‘s1’), the pipeline runs the cwlProcess of GZ, where the input zfile is defined in ‘i1’ with id of “cwl_zfile”. In step 2 (‘s2’), the pipeline runs the cwlProcess of Rs, where the input rfile is from the output of the step 1 (“Uncomp/rfile”) using the format of &lt;step&gt;/&lt;output&gt;. The pipeline output will be defined as the output of the step 2 (“Compile/output”) using the format of &lt;step&gt;/&lt;output&gt; as shown below. o1 &lt;- OutputParam(id = &quot;cwl_cout&quot;, type = &quot;File&quot;, outputSource = &quot;Compile/output&quot;) The cwlWorkflow function is used to initiate the pipeline by specifying the inputs and outputs. Then we can simply use + to connect all steps to build the final pipeline. cwl &lt;- cwlWorkflow(inputs = InputParamList(i1), outputs = OutputParamList(o1)) cwl &lt;- cwl + s1 + s2 cwl ## class: cwlWorkflow ## cwlClass: Workflow ## cwlVersion: v1.0 ## inputs: ## cwl_zfile (File): ## outputs: ## cwl_cout: ## type: File ## outputSource: Compile/output ## steps: ## Uncomp: ## run: Uncomp.cwl ## in: ## zfile: cwl_zfile ## out: ## - rfile ## Compile: ## run: Compile.cwl ## in: ## rfile: Uncomp/rfile ## out: ## - output Let’s run the pipeline. cwl$cwl_zfile &lt;- zzfil r7 &lt;- runCWL(cwl, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success readLines(r7$output) ## [1] &quot;[1] 7 4 6 8 2&quot; Tips: Sometimes, we need to adjust some arguments of certain tools in a pipeline besides of parameter inputs. The function arguments can help to modify arguments for a tool, tool in a pipeline, or even tool in a sub-workflow. For example, arguments(cwl, step = &quot;Uncomp&quot;) &lt;- list(&quot;-d&quot;, &quot;-c&quot;, &quot;-f&quot;) runs(cwl)$Uncomp ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: gzip ## arguments: -d -c -f ## inputs: ## zfile (File): /private/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/sample.R.gz ## outputs: ## rfile: ## type: File ## outputBinding: ## glob: $(inputs.zfile.nameroot) ## stdout: $(inputs.zfile.nameroot) 4.1 Scattering pipeline The scattering feature can specifies the associated workflow step or subworkflow to execute separately over a list of input elements. To use this feature, ScatterFeatureRequirement must be specified in the workflow requirements. Different scatter methods can be used in the associated step to decompose the input into a discrete set of jobs. More details can be found at: https://www.commonwl.org/v1.0/Workflow.html#WorkflowStep. Here is an example to execute multiple R scripts. First, we need to set the input and output types to be array of “File”, and add the requirements. In the “Compile” step, the scattering input is required to be set with the scatter option. i2 &lt;- InputParam(id = &quot;cwl_rfiles&quot;, type = &quot;File[]&quot;) o2 &lt;- OutputParam(id = &quot;cwl_couts&quot;, type = &quot;File[]&quot;, outputSource = &quot;Compile/output&quot;) req1 &lt;- requireScatter() cwl2 &lt;- cwlWorkflow(requirements = list(req1), inputs = InputParamList(i2), outputs = OutputParamList(o2)) s1 &lt;- cwlStep(id = &quot;Compile&quot;, run = Rs, In = list(rfile = &quot;cwl_rfiles&quot;), scatter = &quot;rfile&quot;) cwl2 &lt;- cwl2 + s1 cwl2 ## class: cwlWorkflow ## cwlClass: Workflow ## cwlVersion: v1.0 ## requirements: ## - class: ScatterFeatureRequirement ## inputs: ## cwl_rfiles (File[]): ## outputs: ## cwl_couts: ## type: File[] ## outputSource: Compile/output ## steps: ## Compile: ## run: Compile.cwl ## in: ## rfile: cwl_rfiles ## out: ## - output ## scatter: rfile Multiple R scripts can be assigned to the workflow inputs and executed. cwl2$cwl_rfiles &lt;- c(r4b$output, r4b$output) r8 &lt;- runCWL(cwl2, outdir = tempdir()) ## [1;30mINFO[0m Final process status is success r8$output ## [1] &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/249fd9089dc572177a13e6917496877be4594046&quot; ## [2] &quot;/var/folders/7t/9l4kkf_j2sqbpn321y9g5558z96ck_/T/RtmptDExzb/249fd9089dc572177a13e6917496877be4594046_2&quot; 4.2 Pipeline plot The function plotCWL can be used to visualize the relationship of inputs, outputs and the analysis for a tool or pipeline. plotCWL(cwl) "],["toolpipeline-execution.html", "Chapter 5 Tool/pipeline execution 5.1 Running Tools in Docker 5.2 Running Tools in Cluster server 5.3 Web Application", " Chapter 5 Tool/pipeline execution 5.1 Running Tools in Docker The CWL can work with docker to simplify your software management and communicate files between host and container. The docker container can be defined by the hints or requirements option. d1 &lt;- InputParam(id = &quot;rfile&quot;, type = &quot;File&quot;) req1 &lt;- requireDocker(&quot;r-base&quot;) doc &lt;- cwlProcess(baseCommand = &quot;Rscript&quot;, inputs = InputParamList(d1), stdout = &quot;output.txt&quot;, hints = list(req1)) doc$rfile &lt;- r4$output r6 &lt;- runCWL(doc) The tools defined with docker requirements can also be run locally by disabling the docker option. In case your Rscript depends some local libraries to run, an option from cwltools, “–preserve-entire-environment”, can be used to pass all environment variables. r6a &lt;- runCWL(doc, docker = FALSE, outdir = tempdir(), cwlArgs = &quot;--preserve-entire-environment&quot;) ## [1;30mINFO[0m Final process status is success 5.2 Running Tools in Cluster server The CWL can also work in high performance clusters with batch-queuing system, such as SGE, PBS, SLURM and so on, using the Bioconductor package BiocParallel. Here is an example to submit jobs with “Multicore” and “SGE”. library(BiocParallel) sth.list &lt;- as.list(LETTERS) names(sth.list) &lt;- LETTERS ## submit with multicore result1 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = MulticoreParam(26)) ## submit with SGE result2 &lt;- runCWLBatch(cwl = echo, outdir = tempdir(), inputList = list(sth = sth.list), BPPARAM = BatchtoolsParam(workers = 26, cluster = &quot;multicore&quot;)) 5.3 Web Application 5.3.1 cwlProcess example Here we build a tool with different types of input parameters. e1 &lt;- InputParam(id = &quot;flag&quot;, type = &quot;boolean&quot;, prefix = &quot;-f&quot;, doc = &quot;boolean flag&quot;) e2 &lt;- InputParam(id = &quot;string&quot;, type = &quot;string&quot;, prefix = &quot;-s&quot;) e3 &lt;- InputParam(id = &quot;option&quot;, type = &quot;string&quot;, prefix = &quot;-o&quot;) e4 &lt;- InputParam(id = &quot;int&quot;, type = &quot;int&quot;, prefix = &quot;-i&quot;, default = 123) e5 &lt;- InputParam(id = &quot;file&quot;, type = &quot;File&quot;, prefix = &quot;--file=&quot;, separate = FALSE) e6 &lt;- InputParam(id = &quot;array&quot;, type = &quot;string[]&quot;, prefix = &quot;-A&quot;, doc = &quot;separated by comma&quot;) mulEcho &lt;- cwlProcess(baseCommand = &quot;echo&quot;, id = &quot;mulEcho&quot;, label = &quot;Test parameter types&quot;, inputs = InputParamList(e1, e2, e3, e4, e5, e6), stdout = &quot;output.txt&quot;) mulEcho ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: echo ## inputs: ## flag (boolean): -f ## string (string): -s ## option (string): -o ## int (int): -i 123 ## file (File): --file= ## array (string[]): -A ## outputs: ## output: ## type: stdout ## stdout: output.txt 5.3.2 cwlProcess to Shiny App Some input parameters can be predefined in a list, which will be converted to select options in the webapp. An upload parameter can be used to defined whether to generate an upload interface for the file type option. If FALSE, the upload field will be text input (file path) instead of file input. inputList &lt;- list(option = c(&quot;option1&quot;, &quot;option2&quot;)) app &lt;- cwlShiny(mulEcho, inputList, upload = TRUE) runApp(app) shinyApp "],["rcwlpipelines.html", "Chapter 6 RcwlPipelines 6.1 Rcwl recipes and CWL scripts 6.2 RcwlPipelines core functions 6.3 Tool/pipeline customization 6.4 Build a pipeline", " Chapter 6 RcwlPipelines 6.1 Rcwl recipes and CWL scripts The R scripts to build the CWL tools and pipelines are now residing in a dedicated GitHub repository, which is intended to be a community effort to collect and contribute Bioinformatics tools and pipelines using Rcwl and CWL. Script names are prefixed with tl_ and pl_ for tools and pipelines respectively. 6.2 RcwlPipelines core functions 6.2.1 cwlUpdate The cwlUpdate function syncs the current Rcwl recipes and returns a cwlHub object which contains the most updated Rcwl recipes. The mcols() function returns all related information about each available tool or pipeline. Currently, we have integrated 113 command line tools and 26 pipelines. The recipes will be locally cached, so users don’t need to call cwlUpdate every time unless they want to use a tool/pipeline that is newly added to RcwlPipelines. atls &lt;- cwlUpdate(branch = &quot;dev&quot;) ## sync the tools/pipelines. atls ## cwlHub with 139 records ## cache path: ~/Library/Caches/Rcwl ## # last modified date: 2021-02-22 ## # cwlSearch() to query scripts ## # cwlLoad(&#39;title&#39;) to load the script ## # additional mcols(): rid, rpath, Type, Container, mtime, ... ## ## title ## BFC2772 | pl_alignMerge ## BFC2773 | pl_AnnPhaseVcf ## BFC2774 | pl_BaseRecal ## BFC2775 | pl_bwaAlign ## BFC2776 | pl_bwaMMRecal ## ... ... ## BFC2906 | tl_VarScan2 ## BFC2907 | tl_vcf_expression_annotator ## BFC2908 | tl_vcf_readcount_annotator ## BFC2909 | tl_vep ## BFC2910 | tl_vt_decompose ## Command ## BFC2772 bwaAlign+mergeBamDup ## BFC2773 VCFvep+dVCFcoverage+rVCFcoverage+VCFexpression+PhaseVcf ## BFC2774 BaseRecalibrator+ApplyBQSR+samtools_index+samtools_flagstat+samt... ## BFC2775 bwa+sam2bam+sortBam+idxBam ## BFC2776 bwaAlign+mergeBamDup+BaseRecal ## ... ... ## BFC2906 ## BFC2907 vcf-expression-annotator ## BFC2908 vcf-readcount-annotator ## BFC2909 vep ## BFC2910 vt decompose Currently, we have integrated 113 command line tools and 26 pipelines. table(mcols(atls)$Type) We can also get the commands and docker containers for specific tool or pipeline. mcols(atls)[, c(&quot;Command&quot;, &quot;Container&quot;)] ## DataFrame with 139 rows and 2 columns ## Command Container ## &lt;character&gt; &lt;character&gt; ## 1 bwaAlign+mergeBamDup NA ## 2 VCFvep+dVCFcoverage+.. NA ## 3 BaseRecalibrator+App.. NA ## 4 bwa+sam2bam+sortBam+.. NA ## 5 bwaAlign+mergeBamDup.. NA ## ... ... ... ## 135 serge2016/varscan:v0.. ## 136 vcf-expression-annot.. griffithlab/vatools:.. ## 137 vcf-readcount-annota.. griffithlab/vatools:.. ## 138 vep hubentu/ensembl-vep-.. ## 139 vt decompose hubentu/vt 6.2.2 cwlSearch We can use (multiple) keywords to search for specific tools/pipelines of interest, which internally search the mcols of “rname”, “rpath”, “fpath”, “Command” and “Containers”. Here we show how to search the alignment tool bwa mem. t1 &lt;- cwlSearch(c(&quot;bwa&quot;, &quot;mem&quot;)) t1 ## cwlHub with 1 records ## cache path: ~/Library/Caches/Rcwl ## # last modified date: 2021-02-22 ## # cwlSearch() to query scripts ## # cwlLoad(&#39;title&#39;) to load the script ## # additional mcols(): rid, rpath, Type, Container, mtime, ... ## ## title Command ## BFC2815 | tl_bwa bwa mem mcols(t1) ## DataFrame with 1 row and 14 columns ## rid rname create_time access_time ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 1 BFC2815 tl_bwa 2021-02-26 20:56:55 2021-02-26 20:56:55 ## rpath rtype fpath last_modified_time ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;numeric&gt; ## 1 /Users/qi31566/Libra.. local /Users/qi31566/Libra.. NA ## etag expires Type Command Container ## &lt;character&gt; &lt;numeric&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 1 NA NA tool bwa mem biocontainers/bwa:v0.. ## mtime ## &lt;character&gt; ## 1 2021-02-22 14:45:16 6.2.3 cwlLoad The last core function cwlLoad loads the Rcwl tool/pipeline into the R working environment. The code below loads the tool with a user-defined name bwa to do the read alignment. bwa &lt;- cwlLoad(title(t1)[1]) ## &quot;tl_bwa&quot; bwa &lt;- cwlLoad(mcols(t1)$fpath[1]) ## equivalent to the above. bwa ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: bwa mem ## requirements: ## - class: DockerRequirement ## dockerPull: biocontainers/bwa:v0.7.17-3-deb_cv1 ## inputs: ## threads (int): -t ## RG (string): -R ## Ref (File): ## FQ1 (File): ## FQ2 (File?): ## outputs: ## sam: ## type: File ## outputBinding: ## glob: &#39;*.sam&#39; ## stdout: bwaOutput.sam Now the R tool of bwa is ready to use. 6.3 Tool/pipeline customization To fit users’ specific needs，the existing tool or pipline can be easily customized. Here we use the rnaseq_Sf pipeline to demonstrate how to access and change the arguments of a specific tool inside a pipeline. This pipeline covers RNA-seq reads quality summary by fastQC, alignment by STAR, quantification by featureCounts and quality control by RSeQC. rnaseq_Sf &lt;- cwlLoad(&quot;pl_rnaseq_Sf&quot;) ## fastqc loaded ## STAR loaded ## sortBam loaded ## samtools_index loaded ## samtools_flagstat loaded ## featureCounts loaded ## gtfToGenePred loaded ## genePredToBed loaded ## read_distribution loaded ## geneBody_coverage loaded ## gCoverage loaded ## STAR loaded plotCWL(rnaseq_Sf) There are many default arguments defined for the tool of STAR inside the pipeline. Users might want to change some of them. For example, we can change the value for --outFilterMismatchNmax argument from 2 to 5 for longer reads. arguments(rnaseq_Sf, &quot;STAR&quot;)[5:6] ## [[1]] ## [1] &quot;--outFilterMismatchNmax&quot; ## ## [[2]] ## [1] &quot;2&quot; arguments(rnaseq_Sf, &quot;STAR&quot;)[[6]] &lt;- 5 arguments(rnaseq_Sf, &quot;STAR&quot;)[5:6] ## [[1]] ## [1] &quot;--outFilterMismatchNmax&quot; ## ## [[2]] ## [1] &quot;5&quot; We can also change the docker image for a specific tool (e.g., to a specific version). First, we search for all available docker images for STAR in biocontainers repository. The Source server could be quay or dockerhub. searchContainer(&quot;STAR&quot;, repo = &quot;biocontainers&quot;, source = &quot;quay&quot;) ## DataFrame with 29 rows and 5 columns ## tool repo name last_modified ## &lt;character&gt; &lt;character&gt; &lt;character&gt; &lt;character&gt; ## 2.7.8a--0 STAR biocontainers 2.7.8a--0 Sun, 21 Feb 2021 12:.. ## 2.7.7a--0 STAR biocontainers 2.7.7a--0 Tue, 29 Dec 2020 13:.. ## 2.7.6a--0 STAR biocontainers 2.7.6a--0 Sun, 20 Sep 2020 09:.. ## 2.7.5c--0 STAR biocontainers 2.7.5c--0 Mon, 17 Aug 2020 09:.. ## 2.7.5b--0 STAR biocontainers 2.7.5b--0 Sat, 01 Aug 2020 17:.. ## ... ... ... ... ... ## 2.4.0j--0 STAR biocontainers 2.4.0j--0 Tue, 06 Mar 2018 12:.. ## 2.5.4a--0 STAR biocontainers 2.5.4a--0 Fri, 26 Jan 2018 21:.. ## 2.5.3a--0 STAR biocontainers 2.5.3a--0 Sat, 18 Mar 2017 11:.. ## 2.5.2b--0 STAR biocontainers 2.5.2b--0 Tue, 06 Sep 2016 07:.. ## 2.5.1b--0 STAR biocontainers 2.5.1b--0 Wed, 11 May 2016 08:.. ## size ## &lt;character&gt; ## 2.7.8a--0 7985763 ## 2.7.7a--0 7824392 ## 2.7.6a--0 7820491 ## 2.7.5c--0 7806635 ## 2.7.5b--0 7805390 ## ... ... ## 2.4.0j--0 4734325 ## 2.5.4a--0 9225952 ## 2.5.3a--0 9119736 ## 2.5.2b--0 9086803 ## 2.5.1b--0 11291827 Then, we can change the STAR version into 2.7.8a (tag name: 2.7.8a–0). requirements(rnaseq_Sf, &quot;STAR&quot;)[[1]] ## $class ## [1] &quot;DockerRequirement&quot; ## ## $dockerPull ## [1] &quot;quay.io/biocontainers/star:2.7.3a--0&quot; requirements(rnaseq_Sf, &quot;STAR&quot;)[[1]] &lt;- requireDocker( docker = &quot;quay.io/biocontainers/star:2.7.8a--0&quot;) requirements(rnaseq_Sf, &quot;STAR&quot;)[[1]] ## $class ## [1] &quot;DockerRequirement&quot; ## ## $dockerPull ## [1] &quot;quay.io/biocontainers/star:2.7.8a--0&quot; 6.4 Build a pipeline We can build a pipline using the available tools. Here we demonstrate how to build a simple alignment pipeline with mapping and marking duplicates. First, we check whether the required tools (bwa, samtools and picard markduplicates) are available in RcwlPipelines. tls &lt;- cwlSearch(&quot;bwa|sam2bam|sortBam|samtools_index|markdup&quot;, type = &quot;tool&quot;) tls ## cwlHub with 6 records ## cache path: ~/Library/Caches/Rcwl ## # last modified date: 2021-02-22 ## # cwlSearch() to query scripts ## # cwlLoad(&#39;title&#39;) to load the script ## # additional mcols(): rid, rpath, Type, Container, mtime, ... ## ## title Command ## BFC2814 | tl_bwa_index bwa index ## BFC2815 | tl_bwa bwa mem ## BFC2851 | tl_markdup picard MarkDuplicates ## BFC2877 | tl_sam2bam samtools view ## BFC2881 | tl_samtools_index samtools index ## BFC2887 | tl_sortBam samtools sort Then we load all the required tools. bwa &lt;- cwlLoad(&quot;tl_bwa&quot;) bwa_index &lt;- cwlLoad(&quot;tl_bwa_index&quot;) markdup &lt;- cwlLoad(&quot;tl_markdup&quot;) sam2bam &lt;- cwlLoad(&quot;tl_sam2bam&quot;) samtools_index &lt;- cwlLoad(&quot;tl_samtools_index&quot;) sortBam &lt;- cwlLoad(&quot;tl_sortBam&quot;) Next, we will need to define the input parameters for the pipeline (instead of for each tool). p1 &lt;- InputParam(id = &quot;threads&quot;, type = &quot;int&quot;) p2 &lt;- InputParam(id = &quot;RG&quot;, type = &quot;string&quot;) p3 &lt;- InputParam(id = &quot;Ref&quot;, type = &quot;string&quot;) p4 &lt;- InputParam(id = &quot;FQ1&quot;, type = &quot;File&quot;) p5 &lt;- InputParam(id = &quot;FQ2&quot;, type = &quot;File?&quot;) Then we define the pipeline steps, to connect the inputs and outputs of each tool to form a pipeline. ## bwa s1 &lt;- cwlStep(id = &quot;bwa&quot;, run = bwa, In = list(threads = &quot;threads&quot;, RG = &quot;RG&quot;, Ref = &quot;Ref&quot;, FQ1 = &quot;FQ1&quot;, FQ2 = &quot;FQ2&quot;)) ## sam to bam s2 &lt;- cwlStep(id = &quot;sam2bam&quot;, run = sam2bam, In = list(sam = &quot;bwa/sam&quot;)) ## sort bam s3 &lt;- cwlStep(id = &quot;sortBam&quot;, run = sortBam, In = list(bam = &quot;sam2bam/bam&quot;)) ## mark duplicates s4 &lt;- cwlStep(id = &quot;markdup&quot;, run = markdup, In = list(ibam = &quot;sortBam/sbam&quot;, obam = list( valueFrom=&quot;$(inputs.ibam.nameroot).mdup.bam&quot;), matrix = list( valueFrom=&quot;$(inputs.ibam.nameroot).markdup.txt&quot;))) ## index bam s5 &lt;- cwlStep(id = &quot;idxBam&quot;, run = samtools_index, In = list(bam = &quot;markdup/mBam&quot;)) Last, we will define the pipeline outputs and connect all the above defined steps into a new pipeline. req1 &lt;- requireStepInputExpression() req2 &lt;- requireJS() ## outputs o1 &lt;- OutputParam(id = &quot;Bam&quot;, type = &quot;File&quot;, outputSource = &quot;markdup/mBam&quot;) o2 &lt;- OutputParam(id = &quot;Idx&quot;, type = &quot;File&quot;, outputSource = &quot;idxBam/idx&quot;) ## cwlWorkflow Align &lt;- cwlWorkflow(requirements = list(req1, req2), inputs = InputParamList(p1, p2, p3, p4, p5), outputs = OutputParamList(o1, o2)) ## build pipeline Align &lt;- Align + s1 + s2 + s3 + s4 + s5 Now the pipeline is successfully built and ready for use. We can visualize the pipeline with plotCWL from the Rcwl package. plotCWL(Align) "],["dnaseq-alignment.html", "Chapter 7 DNAseq alignment", " Chapter 7 DNAseq alignment The pipeline tl_bwaMRecal can be used to preprocess the fastq files from DNA sequencing. It can take paired fastq files, read groups from multiple batches as input. bwaMRecal &lt;- cwlLoad(&quot;pl_bwaMRecal&quot;) ## markdup loaded inputs(bwaMRecal) ## inputs: ## outBam (string): ## RG (string): ## threads (int): ## Ref (File): ## FQ1s (File): ## FQ2s (File): ## knowSites: ## type: array ## prefix: The pipeline includes three steps: BWA alignment, mark duplicate, and base recalibration. The steps can be a single tool or a sub-pipeline that includes several tools each. runs(bwaMRecal) ## List of length 3 ## names(3): bwaAlign markdup BaseRecal bwaAlign: BWA alignment step is a sub-pipeline which includes the following tools: runs(runs(bwaMRecal)[[1]]) ## List of length 4 ## names(4): bwa sam2bam sortBam idxBam bwa: to align fastqs and read groups to reference genome with bwa. sam2bam: to convert the alignments from “sam” to “bam” format with samtools. sortBam: to sort the “bam” file by coordinates with samtools. idxBam: To index “bam” file with samtools. markdup: MarkDuplicates runs a single command line tool Picard that identifies duplicate reads. runs(bwaMRecal)[[2]] ## class: cwlProcess ## cwlClass: CommandLineTool ## cwlVersion: v1.0 ## baseCommand: picard MarkDuplicates ## requirements: ## - class: DockerRequirement ## dockerPull: quay.io/biocontainers/picard:2.21.1--0 ## inputs: ## ibam (File): I= ## obam (string): O= ## matrix (string): M= ## outputs: ## mBam: ## type: File ## outputBinding: ## glob: $(inputs.obam) ## Mat: ## type: File ## outputBinding: ## glob: $(inputs.matrix) BaseRecal: Alignment recalibration is a sub-pipeline that runs several tools from GATK toolkit. runs(runs(bwaMRecal)[[3]]) ## List of length 5 ## names(5): BaseRecalibrator ApplyBQSR samtools_index samtools_flagstat samtools_stats BaseRecalibrator and ApplyBQSR: alignment recalibration by GATK toolkit. samtools_index: to index bam file with samtools. samtools_flagstat and samtools_stats: to summarize alignments with samtools. The output of bwaMRecal pipeline includes the duplicates matrix from markdup step, final processed bam files and flag summary files from BaseRecal step. outputs(bwaMRecal) ## outputs: ## BAM: ## type: File ## outputSource: BaseRecal/rcBam ## matrix: ## type: File ## outputSource: markdup/Mat ## flagstat: ## type: File ## outputSource: BaseRecal/flagstat ## stats: ## type: File ## outputSource: BaseRecal/stats "],["dnaseq-variant-calling.html", "Chapter 8 DNAseq variant calling", " Chapter 8 DNAseq variant calling to be added. "],["bulk-rnaseq.html", "Chapter 9 Bulk RNAseq 9.1 Prepare data 9.2 Submit parallel jobs 9.3 QC Summary 9.4 Abundances summary 9.5 transcriptome quantification", " Chapter 9 Bulk RNAseq This pipeline covers RNA-seq reads quality summary by fastQC, alignment by STAR, quantification by featureCounts and quality control by RSeQC. rnaseq_Sf &lt;- cwlLoad(&quot;pl_rnaseq_Sf&quot;) ## fastqc loaded ## STAR loaded ## sortBam loaded ## samtools_index loaded ## samtools_flagstat loaded ## featureCounts loaded ## gtfToGenePred loaded ## genePredToBed loaded ## read_distribution loaded ## geneBody_coverage loaded ## gCoverage loaded ## STAR loaded plotCWL(rnaseq_Sf) The pipeline includes 10 steps, each step runs a single command as follows: runs(rnaseq_Sf) ## List of length 10 ## names(10): fastqc STAR sortBam ... genePredToBed r_distribution gCoverage fastqc: to run quality summary for raw fastqs with base command fastqc. STAR: to align fastqs with STAR. sortBam: to sort bam files with samtools. samtools_index: to index aligned bam file with samtools. samtools_flagstat: to summarize alignment flags with samtools. featureCounts: to quantify gene abundance with featureCounts. gtfToGenePred: to convert GTF annotation to ‘genePred’ format with RSeQC. genePredToBed: to convert ‘genePred’ annotation to ‘bed’ format with RSeQC. r_distribution: to run read distribution over genome features with RSeQC. gCoverage: to summarize read coverage over gene body with RSeQC. The rnaseq_Sf pipepine output includes the QC result from fastqc step, indexed bam files from samtools_index step, log and read counts from STAR step, flag summary from samtools_flagstat step, feature counts from featureCounts step, alignment QC results from RSeQC steps. outputs(rnaseq_Sf) ## outputs: ## out_fastqc: ## type: File[] ## outputSource: fastqc/QCfile ## out_BAM: ## type: File ## outputSource: samtools_index/idx ## out_Log: ## type: File ## outputSource: STAR/outLog ## out_Count: ## type: File ## outputSource: STAR/outCount ## out_stat: ## type: File ## outputSource: samtools_flagstat/flagstat ## out_count: ## type: File ## outputSource: featureCounts/Count ## out_distribution: ## type: File ## outputSource: r_distribution/distOut ## out_gCovP: ## type: File ## outputSource: gCoverage/gCovPDF ## out_gCovT: ## type: File ## outputSource: gCoverage/gCovTXT 9.1 Prepare data An RNASeq test data with paired-end fastq files for 6 samples can be downloaded from genomedata. Create a local directory and follow the code below to download and uncompress. dir.create(&quot;data/RNAseq&quot;, recursive = TRUE) download.file(&quot;http://genomedata.org/rnaseq-tutorial/HBR_UHR_ERCC_ds_5pc.tar&quot;, &quot;data/RNAseq/HBR_UHR_ERCC_ds_5pc.tar&quot;) untar(&quot;data/RNAseq/HBR_UHR_ERCC_ds_5pc.tar&quot;, exdir = &quot;data/RNAseq/&quot;) 9.2 Submit parallel jobs Powered by BiocParallel,Rcwl supports parallel job running for multiple samples using the runCWLBatch function. The BPPARAM argument in runCWLBatch() defines the parallel parameters. It can be defined by BiocParallel::BatchtoolsParam function, where the cluster argument takes different values for different cluster job manager, such as “multicore”, “sge” and “slurm”. More details about available options can be checked by ?BiocParallel::BatchtoolsParam. library(BiocParallel) bpparam &lt;- BatchtoolsParam(workers = 2, cluster = &quot;sge&quot;, template = batchtoolsTemplate(&quot;sge&quot;)) In the following example, we are using “multicore” for the parallel running. bpparam &lt;- BatchtoolsParam( workers = 2, cluster = &quot;multicore&quot;) When submitting parallel jobs using runCWLBatch function, two other arguments: inputList and paramList, need to be defined. The inputList argument is required to be a list of input parameter values for samples that are to be computed parallelly. NOTE that the names of the list must be consistent with the ids of input parameters. In this example, they are: in_seqfiles: A list with the fastq files of each sample in each element. The names of the list need to be defined and can be the sample IDs. The length of the list will be the same as the number of samples, so that the list of samples can be assigned to different nodes for parallel computing. Here we only use 2 samples for demonstration purposes. in_prefix: A list of sample IDs. files &lt;- normalizePath(list.files(&quot;data/RNAseq/&quot;, &quot;.gz&quot;, full.names = TRUE))[1:4] files &lt;- tapply(files, substring(basename(files), 1, 8), as.list) inputList &lt;- list(in_seqfiles = files, in_prefix = as.list(names(files))) The paramList argument is required to be a list of input parameter values that are to be shared for all parallelly running samples. In this example, they are: in_genomeDir: The reference genome indexes for STAR. in_GTFfile: The gene annotation file in GTF format. in_runThreadN: The number of threads to run for each job. paramList &lt;- list( in_genomeDir = &quot;data/resources/GRCh38_chr22&quot;, in_GTFfile = &quot;data/resources/GRCh38_chr22/gencode.v32.annotation_chr22.gtf&quot;, in_runThreadN = 2 ) Here we can also modify the default argument values in some steps of a pipeline. For example, arguments(rnaseq_Sf, &quot;STAR&quot;)[1:2] ## [[1]] ## [1] &quot;--outFilterMultimapNmax&quot; ## ## [[2]] ## [1] &quot;3&quot; arguments(rnaseq_Sf, &quot;STAR&quot;)[[2]] &lt;- &quot;2&quot; arguments(rnaseq_Sf, &quot;STAR&quot;)[1:2] ## [[1]] ## [1] &quot;--outFilterMultimapNmax&quot; ## ## [[2]] ## [1] &quot;2&quot; Now that the fastqc files of each sample will be submitted to different nodes to run the whole pipeline parallelly. res &lt;- runCWLBatch(cwl = rnaseq_Sf, outdir = &quot;output/RNAseq_bulk&quot;, inputList = inputList, paramList = paramList, BPPARAM = bpparam, showLog = TRUE) Pipeline results are collected in the output directory (defined in outdir) for each sample. dir(&quot;output/RNAseq_bulk&quot;) ## [1] &quot;HBR_Rep1&quot; &quot;HBR_Rep2&quot; 9.3 QC Summary The tool multiqc can aggregate results from the multiple outputs of the pipeline and generate a single page report, which also was implemented in the RcwlPipelines package: multiqc$dir &lt;- &quot;output/RNASeq_bulk&quot; multiqc We can also run the tool using Rcwl locally with the option docker = TRUE: runCWL(multiqc, stderr = &quot;&quot;, Args = &quot;--preserve-entire-environment&quot;, docker = FALSE) 9.4 Abundances summary Here we use the R/Bioconductor package edgeR functions to calculate the RPKM and CPM abundances. countfiles &lt;- list.files(&quot;output/RNAseq_bulk&quot;, &quot;featureCounts.txt$&quot;, recursive = TRUE, full.names = TRUE) samples &lt;- basename(dirname(countfiles)) rExp &lt;- function(countfile){ count1 &lt;- read.table(countfile, header = TRUE)[, c(1,6,7)] rpkm1 &lt;- edgeR::rpkm(count1[,3,drop=F], gene.length = count1$Length) cpm1 &lt;- edgeR::cpm(count1[,3]) count1 &lt;- data.frame(count1, rpkm1, cpm1) colnames(count1)[3:5] &lt;- c(&quot;count&quot;, &quot;rpkm&quot;, &quot;cpm&quot;) return(count1) } head(rExp(countfiles[1])) ## Geneid Length count rpkm cpm ## 1 ENSG00000223972.5 1735 0 0 0 ## 2 ENSG00000227232.5 1351 0 0 0 ## 3 ENSG00000278267.1 68 0 0 0 ## 4 ENSG00000243485.5 1021 0 0 0 ## 5 ENSG00000284332.1 138 0 0 0 ## 6 ENSG00000237613.2 1219 0 0 0 We combine the files into one file, and then the data is ready for statistical analysis using R/Bioconductor packages, such as DESeq2 or edgeR. for(i in 1:length(samples)) { exp1 &lt;- rExp(countfiles[i]) write.table(exp1, file = paste0(&quot;output/RNAseq_bulk&quot;, samples[i], &quot;/&quot;, samples[i], &quot;_abundance.tsv&quot;), row.names = FALSE, quote = FALSE, sep = &quot;\\t&quot;) } 9.5 transcriptome quantification There are many tools available for transcriptome quantification, such as kallisto, StringTie, salmon, and Trinity. Here show the usage of Kallisto and salmon. 9.5.1 Kallisto The kallisto is a tool to quantify transcript abundance with raw fastq reads and indexed reference transcriptomes. The Rcwl tool of kallisto_index below is used to build an index file from reference transcriptome fasta. kallisto_index &lt;- cwlLoad(&quot;tl_kallisto_index&quot;) inputs(kallisto_index) kallisto_index$fasta &lt;- &quot;data/resources/gencode.v33.transcripts.fa&quot; kallisto_index$index &lt;- &quot;gencode.v33.transcripts_kallisto&quot; runCWL(kallisto_index, outdir = &quot;data/resources/kallisto&quot;, showLog = TRUE) The Rcwl tool kallisto_quant runs the quantification algorithm to estimate the transcripts expression abundances. kallisto_quant &lt;- cwlLoad(&quot;tl_kallisto_quant&quot;) inputList &lt;- list(fastq = files) paramList &lt;- list(index = &quot;data/resources/gencode.v33.transcripts_kallisto&quot;, threads = 16) bpparam &lt;- BatchtoolsParam(workers = length(samples), cluster = &quot;multicore&quot;) res2 &lt;- runCWLBatch(kallisto_quant, outdir = &quot;output/RNAseq_bulk/kallisto&quot;, inputList, paramList, BPPARAM = bpparam, log = TRUE, logdir = &quot;.&quot;) Then the tool results are collected here: list.files(&quot;output/RNAseq_bulk/kalisto&quot;, &quot;abundance&quot;) ## character(0) 9.5.2 salmon To be added. "],["single-cell-rnaseq.html", "Chapter 10 single cell RNAseq", " Chapter 10 single cell RNAseq To be added. "],["mirna.html", "Chapter 11 miRNA", " Chapter 11 miRNA The miRDeep2 is one of the most popular tools for discovering known and novel miRNAs from small RNA sequencing data. We have wrapped the mapping and quantification steps into an Rcwl pipeline which is ready to load and use. More details about miRDeep2 can be found here: https://github.com/rajewsky-lab/mirdeep2. miRDeep2PL &lt;- cwlLoad(&quot;pl_miRDeep2PL&quot;) ## miRMapper loaded ## miRDeep2 loaded plotCWL(miRDeep2PL) Here We also use the data from the above GitHub repository as an example. https://github.com/rajewsky-lab/mirdeep2/tree/master/tutorial_dir git2r::clone(&quot;https://github.com/rajewsky-lab/mirdeep2&quot;, &quot;data/miRNA&quot;) list.files(&quot;data/miRNA/tutorial_dir&quot;) 11.0.1 Reference index First, we need to build indexes for the miRNA reference with the Rcwl tool bowtie_build. This is only required to be performed once for each refernce genome. bowtie_build &lt;- cwlLoad(&quot;tl_bowtie_build&quot;) inputs(bowtie_build) ## inputs: ## ref (File): ## outPrefix (string): bowtie_build$ref &lt;- &quot;data/miRNA/tutorial_dir/cel_cluster.fa&quot; bowtie_build$outPrefix &lt;- &quot;cel_cluster&quot; idxRes &lt;- runCWL(bowtie_build, outdir = &quot;output/miRNA/genome&quot;, showLog = TRUE, logdir = &quot;output/miRNA&quot;) Then the indexed reference files are generated in the output directory defined in outdir. file.copy(&quot;data/miRNA/tutorial_dir/cel_cluster.fa&quot;, &quot;output/miRNA/genome/cel_cluster.fa&quot;) ## Warning in file.create(to[okay]): cannot create file &#39;output/miRNA/genome/ ## cel_cluster.fa&#39;, reason &#39;No such file or directory&#39; ## [1] FALSE dir(&quot;output/miRNA/genome&quot;) ## character(0) 11.0.2 Run miRDeep2 pipeline To run the pipeline for all samples parallelly, we need to prepare the inputs for arguments of inputList and paramList. inputs(miRDeep2PL) ## inputs: ## reads (File): ## format (string): -c ## adapter (string): ## len (int): 18 ## genome (File): ## miRef ( File|string ): ## miOther ( File|string ): ## precursors ( File|string ): ## species (string): To mimic multiple samples, here we just repeat to use the input reads as if they are two different samples. reads &lt;- list(sample1 = &quot;data/miRNA/tutorial_dir/reads.fa&quot;, sample2 = &quot;data/miRNA/tutorial_dir/reads.fa&quot;) inputList &lt;- list(reads = reads) paramList &lt;- list(adapter = &quot;TCGTATGCCGTCTTCTGCTTGT&quot;, genome = &quot;output/miRNA/genome/cel_cluster.fa&quot;, miRef = &quot;data/miRNA/tutorial_dir/mature_ref_this_species.fa&quot;, miOther = &quot;data/miRNA/tutorial_dir/mature_ref_other_species.fa&quot;, precursors = &quot;data/miRNA/tutorial_dir/precursors_ref_this_species.fa&quot;, species = &quot;C.elegans&quot;) Let’s run the pipeline with two computing nodes. mirRes &lt;- runCWLBatch(miRDeep2PL, outdir = &quot;output/miRNA&quot;, inputList, paramList, BPPARAM = BatchtoolsParam( workers = 2, cluster = &quot;multicore&quot;)) The results are collected in the output directory defined in the outdir. dir(&quot;output/miRNA/sample1&quot;) ## character(0) "],["references.html", "References", " References "]]
